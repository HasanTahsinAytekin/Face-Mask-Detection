{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resim Üzerinde Maske Tanımlama\n",
    "Eğitilen **Maske Tanıma Modeli**, gerçek uygulamalarda kullanılabilecek olgunluktadır. Bu amaçla, herhangi bir resim içindeki kişilerin maske takıp takmadıklarının belirlenmesi için üç benzer uygulama geliştirilmiştir. \n",
    "Geliştirilen maske tanımlama modelini kullanabilmek için, öncelikle resimlerdeki yüz nesnelerinin belirlenmesi gerekmektedir. Resimlerdeki yüz belirleme algoritması, bu ödevin konusu olmadığı için, bu amaçla kullanımı genel kabul görmüş üç farklı algoritma seçilmiş ve maske tanımlaması, seçilmiş olan üç farklı yüz belirleme algoritmasının çıktıları üzerinde denenmiştir. Bu amaçla seçilen üç farklı Python algoritma kütüphanesi şunlardır:\n",
    "* OpenCV Haar\n",
    "* OpenCV DNN\n",
    "* MTCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Haar\n",
    "OpenCV, yüz algılamada **Haar Kademeleri**ni kullanmaktadır. Haar kademelerini kullanarak yüz algılama, kademeli işlevin bir dizi giriş verisiyle eğitildiği makine öğrenimi tabanlı bir yaklaşımdır. OpenCV halihazırda yüz, gözler, gülümsemeler vb. İçin önceden eğitilmiş birçok sınıflandırıcı içermektedir.\n",
    "\n",
    "OpenCv’nin Haar sınıflandırıcısını kullanabilmek için, OpenCv’nin GitHub deposunda bulunan eğitimli sınıflandırıcı XML dosyasının (haarcascade_frontalface_default.xml) yazılım ortamına indirilmesi gerekmektedir. Bu dosya, <haarcascade_frontalface_default.xml> olarak proje OpenCV GitHub Repository’sindeki <face_detector> klasöründe de mevcuttur.\n",
    "(https://github.com/opencv/opencv/tree/master/data/haarcascades)\n",
    "\n",
    "# OpenCV Haar Sınıflandırıcısı Kullanan Yüz Maskesi Tanımlama Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceMaskDetection_Picture_With_OpenCV_HaarCascade(image_file, model_file, cascade_classifier):\n",
    "    faceCascade = cv2.CascadeClassifier(cascade_classifier)\n",
    "\n",
    "    model = load_model(model_file)\n",
    "\n",
    "    image = plt.imread(image_file)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    print(\"> {0} adet yüz bulundu!\".format(len(faces)))\n",
    "\n",
    "    # Bulunan yüzleri dörgen ile çerçeveleyelim\n",
    "    for (x, y, w, h) in faces:\n",
    "        startX = x\n",
    "        startY = y\n",
    "        endX = x + w\n",
    "        endY = y + h\n",
    "\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        face = img_to_array(face)\n",
    "        face = preprocess_input(face)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "\n",
    "        # Elde edilen yüzü, maske varlığını test etmek için modelimize yolluyoruz\n",
    "        (withoutMask, mask) = model.predict(face)[0]\n",
    "\n",
    "        # Modelimizin değerlendirmesi sonucunda elde ettiğimiz sınıf etiketlerini\n",
    "        #   kullanarak, sonuç ve sonuç karesinin rengini belirliyoruz\n",
    "        label = \"Maske Var\" if mask > withoutMask else \"Maske Yok\"\n",
    "        color = (0, 255, 0) if label == \"Maske Var\" else (0, 0, 255)\n",
    "\n",
    "        # Oluşturulan etikete modelin döndürdüğü olasılığı da ekliyoruz\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        # Çıktı çerçevesine etiketi ve yüzü çevreleyen dörtgeni çiziyoruz\n",
    "        cv2.putText(image, label, (startX, startY - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "    # İşlenen görüntüyü sonuç olarak ekrana ve diske yazdırıyoruz\n",
    "    cv2.putText(image, \"[With OpenCV CascadeClassifier] *** NOT OK ***\", (5,20), cv2.FONT_HERSHEY_SIMPLEX , 0.5, (255, 0, 0), 1)\n",
    "    cv2.imwrite(\"DetectMask_OpenCV_HaarCascade.jpg\", image, )\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV DNN\n",
    "OpenCV Deep Neural Networks (**OpenCV DNN**), Single Shot-Multibox Detector (SSD) tabanlı bir Caffe modelidir ve omurgası olarak ResNet-10 mimarisini kullanır. OpenCV 3.3 sonrası derin sinir ağı modülünde tanıtılmıştır.\n",
    "\n",
    "OpenCV DNN’i kullanabilmek için gereken eğitimli DNN dosyası <deploy.prototxt> ve hesaplanmış hazır ağırlıkları içeren <res10_300x300_ssd_iter_140000.caffemodel> dosyasını OpenCv’nin GitHub deposundan yazılım geliştirme ortamına indirilmelidir.\n",
    "(https://github.com/opencv/opencv/tree/master/samples/dnn)\n",
    "\n",
    "\n",
    "# OpenCV DNN Sınıflandırıcısı Kullanan Yüz Maskesi Tanımlama Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceMaskDetection_Picture_With_OpenCV_DNN(image_file, model_file, prototxt_file, weights_file, face_confidence_probability):\n",
    "\t#\n",
    "\tprint(\"> DNN yüz tanımlama modeli yükleniyor...\")\n",
    "\t# OpenCV DNN modelin diskten okuyalım\n",
    "\tnet = cv2.dnn.readNet(prototxt_file, weights_file)\n",
    "\n",
    "\t# Maske belirleme amacıyla oluşturduğumuz modeli diskten okuyalım\n",
    "\tprint(\"> Yüz maskesi tanımlama modeli yükleniyor...\")\n",
    "\tmodel = load_model(model_file)\n",
    "\n",
    "\timage = cv2.imread(image_file)\n",
    "\n",
    "\t(h, w) = image.shape[:2]\n",
    "\n",
    "\t# Yüklenen görüntüden blop oluşturalım\n",
    "\tblob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
    "\t\t(104.0, 177.0, 123.0))\n",
    "\n",
    "\t# Oluşturulan blob'u var olan potansiyel yüzleri algılamak için DNN'e yollayalım\n",
    "\tprint(\"> Yüzler algılanıyor...\")\n",
    "\tnet.setInput(blob)\n",
    "\tdetections = net.forward()\n",
    "\n",
    "\tprint(\"> {0} adet yüz olmaya aday nesne bulundu!\".format(detections.shape[2]))\n",
    "\n",
    "\tfaceCount = 0\n",
    "\t# Bulunan bütün yüzler için\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\t# Geri yollanan nesnenin yüz olma olasılığını alalım\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# Yüzdesi parametre olarak yolladığımız değerden büyük olan yüzleri inceleyelim\n",
    "\t\tif confidence > face_confidence_probability:\n",
    "\t\t\t# Yüz nesnesinin etrafına çizeceğimiz diktörgen için ilgili koordinatlarını belirleyelim\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t# Belirlediğimiz koordinatlar dışa taşmasın\n",
    "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
    "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "\t\t\t# Yüzü oluşturduğumuz modele yollamak için hazırlık yapalım\n",
    "\t\t\tface = image[startY:endY, startX:endX]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\t\t\tface = np.expand_dims(face, axis=0)\n",
    "\n",
    "\t\t\t# Elde edilen final görüntüyü işlemek için oluşturduğumuz modelimize yollayalım\n",
    "\t\t\t(withoutMask, mask) = model.predict(face)[0]\n",
    "\n",
    "\t\t\t# Modelimizin değerlendirmesi sonucunda elde ettiğimiz sınıf etiketlerini\n",
    "\t\t\t# \tkullanarak, sonuç ve sonuç karesinin rengini belirliyoruz\n",
    "\t\t\tlabel = \"Maske Var\" if mask > withoutMask else \"Maske Yok\"\n",
    "\t\t\tcolor = (0, 255, 0) if label == \"Maske Var\" else (0, 0, 255)\n",
    "\n",
    "\t\t\t# Oluşturulan etikete modelin döndürdüğü olasılığı da ekliyoruz\n",
    "\t\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "\t\t\t# Çıktı çerçevesine etiketi ve yüzü çevreleyen dörtgeni çiziyoruz\n",
    "\t\t\tcv2.putText(image, label, (startX, startY - 10),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1)\n",
    "\t\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "\t\t\t#\n",
    "\t\t\tfaceCount=faceCount+1\n",
    "\n",
    "\tprint(\"> {0} adet yüz belirlendi!\".format(faceCount))\n",
    "\t# İşlenen görüntüyü sonuç olarak ekrana ve diske yazdırıyoruz\n",
    "\tcv2.putText(image, \"[With OpenCV DNN] *** NOT OK ***\", (5,20), cv2.FONT_HERSHEY_SIMPLEX , 0.5, (255, 0, 0), 1)\n",
    "\tcv2.imwrite(\"DetectMask_OpenCV_DNN.jpg\", image, )\n",
    "\tcv2.imshow(\"Output\", image)\n",
    "\tcv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTCNN (Multi-task Cascaded Convolutional Neural Networks)\n",
    "MTCNN (**Multi-task Cascaded Convolutional Neural Networks**), bir görüntüdeki yüzlerin sınırlayıcı kutularını 5 Noktalı Yüz İşaretleri ile algılayan 3 aşamadan oluşan bir algoritmadır. Her aşama, girişlerini bir CNN (**Convolutional Neural Network**)'den geçirerek algılama sonuçlarını kademeli olarak iyileştirerek sınırlayıcı kutu adaylarını puanlarıyla birlikte döndürür. Değerlendirilen üç algoritmadan, belirli bir resimde en iyi sonucu bu algoritma vermektedir.\n",
    "\n",
    "# MTCNN Sınıflandırıcısı Kullanan Yüz Maskesi Tanımlama Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceMaskDetection_Picture_With_MTCNN(image_file, model_file):\n",
    "    detector=MTCNN()\n",
    "\n",
    "    model = load_model(model_file)\n",
    "\n",
    "    image = plt.imread(image_file)\n",
    "\n",
    "    faces=detector.detect_faces(image)\n",
    "\n",
    "    print(\"> {0} adet yüz bulundu!\".format(len(faces)))\n",
    "\n",
    "    for face in faces:\n",
    "        bounding_box = face['box']\n",
    "\n",
    "        startX = bounding_box[0]\n",
    "        startY = bounding_box[1]\n",
    "        endX = bounding_box[0]+bounding_box[2]\n",
    "        endY = bounding_box[1] + bounding_box[3]\n",
    "\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        face = img_to_array(face)\n",
    "        face = preprocess_input(face)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "\n",
    "        # Elde edilen yüzü, maske varlığını test etmek için modelimize yolluyoruz\n",
    "        (withoutMask, mask) = model.predict(face)[0]\n",
    "\n",
    "        # Modelimizin değerlendirmesi sonucunda elde ettiğimiz sınıf etiketlerini\n",
    "        #   kullanarak, sonuç ve sonuç karesinin rengini belirliyoruz\n",
    "        label = \"Maske Var\" if mask > withoutMask else \"Maske Yok\"\n",
    "        color = (0, 255, 0) if label == \"Maske Var\" else (0, 0, 255)\n",
    "\n",
    "        # Oluşturulan etikete modelin döndürdüğü olasılığı da ekliyoruz\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        # Çıktı çerçevesine etiketi ve yüzü çevreleyen dörtgeni çiziyoruz\n",
    "        cv2.putText(image, label, (startX, startY - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1)\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "    # İşlenen görüntüyü sonuç olarak ekrana ve diske yazdırıyoruz\n",
    "    cv2.putText(image, \"[With MTCNN] *** OK ***\", (5,20), cv2.FONT_HERSHEY_SIMPLEX , 0.5, (255, 0, 0), 1)\n",
    "    cv2.imwrite(\"DetectMask_MTCNN.jpg\", image, )\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Haar Sınıflandırıcı ile Maske Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 4 adet yüz bulundu!\n"
     ]
    }
   ],
   "source": [
    "FaceMaskDetection_Picture_With_OpenCV_HaarCascade(\n",
    "    \"test_images/0072.jpg\", \n",
    "    \"mask_detector.model\", \n",
    "    r'face_detector\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV DNN Sınıflandırıcı ile Maske Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> DNN yüz tanımlama modeli yükleniyor...\n",
      "> Yüz maskesi tanımlama modeli yükleniyor...\n",
      "> Yüzler algılanıyor...\n",
      "> 200 adet yüz olmaya aday nesne bulundu!\n",
      "> 4 adet yüz belirlendi!\n"
     ]
    }
   ],
   "source": [
    "FaceMaskDetection_Picture_With_OpenCV_DNN(\n",
    "    \"test_images/0072.jpg\", \n",
    "    \"mask_detector.model\", \n",
    "    r'face_detector\\deploy.prototxt', \n",
    "    r'face_detector\\res10_300x300_ssd_iter_140000.caffemodel', \n",
    "    0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTCNN Sınıflandırıcı ile Maske Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000223EC67F670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> 5 adet yüz bulundu!\n"
     ]
    }
   ],
   "source": [
    "FaceMaskDetection_Picture_With_MTCNN(\n",
    "    \"test_images/0072.jpg\", \n",
    "    \"mask_detector.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
