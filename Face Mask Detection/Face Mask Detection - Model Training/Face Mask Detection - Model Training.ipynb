{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eğitim İçin Kullanılacak Toplu Tensör Verilerinin Oluşturulması\n",
    "**TensorFlow**, derin sinir ağlarının eğitimi ve çıkarımına odaklanan makine öğrenimi için ücretsiz ve açık kaynak kodlu özel bir yazılım kütüphanedir (Wikipedia, TensorFlow, 2020). İçerik olarak veri akışına ve türevlenebilir (differentiable) programlamaya (Wikipedia, Differentiable programming, 2020) dayalı sembolik bir matematik kitaplığıdır. Google'da hem araştırma hem de üretim için kullanılır.\n",
    "\n",
    "Tensörler sadece tek bir veri tipinden oluşan çok boyutlu dizinlerdir. NumPy kullanımı ile bir ilişkilendirme yapılırsa, tensörler (bir nevi) np.arrays gibidir. Tüm tensörler, Python sayıları ve dizeleri gibi değişmezdir: Bir tensörün içeriği asla güncellenemez, sadece yeni bir tane yaratılabilir (TensorFlow, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maske Tanımlama Modelinin Oluşturulması\n",
    "Tanımlanan model **MobileNetV2** üzerine kurulacaktır. Bu model ters artıklar ve doğrusal darboğazlar içeren sınıflandırma, tespit ve segmentasyon için kullanılmaktadır.\n",
    "\n",
    "# Yüz Maskesi Tanıma Modeli Tanımlama Sınıfı\n",
    "Bu sınıf ile model oluşturulmakta ve çalışma özellikleri belirlenmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMaskModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FaceMaskModel, self).__init__()\n",
    "        # Temel model\n",
    "        self.AP = AveragePooling2D(pool_size=(7, 7))\n",
    "        self.F = Flatten(name=\"flatten\")\n",
    "        self.D1 = Dense(128, activation=\"relu\")\n",
    "        self.DRO = Dropout(0.5)\n",
    "        self.D2 = Dense(2, activation=\"softmax\")\n",
    "\n",
    "    def call(self, base_model):\n",
    "        # Temel modelin üzerine kurulacak katmanları belirliyoruz\n",
    "        head_model = base_model.output\n",
    "        head_model = self.AP(head_model)\n",
    "        head_model = self.F(head_model)\n",
    "        head_model = self.D1(head_model)\n",
    "        head_model = self.DRO(head_model)\n",
    "        head_model = self.D2(head_model)\n",
    "        #\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        #\n",
    "        # Ana yüz tanıma modelini, temel modelin üzerine yerleştiriyoruz,\n",
    "        #   böylece eğitim için kullanacağımız modelin tamamı oluşuyor.\n",
    "        return Model(inputs=base_model.input, outputs=head_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yüz Maskesi Tanımlama Modeli Eğitimi\n",
    "Modelin tanımlaması yapıldıktan sonra tanımlanan modelin eğitiminin yapılması gerekmektedir. Bu amaçla, oluşturulan modeli derlemeden önce, model derlemesinde kullanılacak olan optimize edici belirlenmelidir. Bu amaçla belirlenen **Adam** algoritması tanımlı bir nesne olarak sisteme yüklenmelidir.\n",
    "\n",
    "Adam, düşük dereceli momentlerin uyarlanabilir tahminlerine dayanan, stokastik amaç fonksiyonlarının birinci dereceden gradyan tabanlı optimizasyonu için bir algoritmadır. Yöntemin uygulanması basittir, hesaplama açısından etkilidir, çok az bellek gereksinimi vardır, gradyanların diyagonal olarak yeniden ölçeklendirilmesiyle değişmez ve veri ve/veya parametreler açısından büyük boyutlu problemler için çok uygundur. Yöntem, aynı zamanda, sabit olmayan hedefler ve çok gürültülü ve/veya seyrek gradyanlı problemler için de uygundur. Hiper parametrelerin sezgisel yorumları vardır ve genelde çok az ayarlama gerektirir (Kingma & Ba, 2015).\n",
    "\n",
    "Adam algoritması bir nesne olarak sisteme yüklendikten sonra, kayıplar için ‘**binary_crossentropy**’, optimazer olarak **Adam** ve metrics olarak ‘**accuracy**’ parametre ayarları ile, oluşturulan model derlenmektedir.\n",
    "\n",
    "Derlenen model daha önce hazırlanan parametreler ile 30 döngü döneminden oluşan 32’lik yığın partileriyle çalıştırılarak, geliştirilmiş olan model eğitilmekte ve eğitim sırasında gerçekleşen işlemlerin geçmiş hikayeleri bir nesneye yüklenmektedir.\n",
    "\n",
    "Eğitim işlemi bittikten sonra ise, eğitilmiş olan maske tanımlama modeli daha sonra değişik uygulamalarda kullanılabilmesi  için dizin haline getirilerek (serialize) diske kaydedilmektedir.\n",
    "\n",
    "# Yüz Maskesi Modeli Eğitimi Sınıfı\n",
    "Bu sınıf ile, daha önce tanımlanmış yüz tanıma modeli eğitilmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMaskTraining():\n",
    "    def __init__(self):\n",
    "        # Varsayılanları oluştur (Class Variables)\n",
    "        self.image_directory = r'C:\\ML\\Datasets\\FaceMaskDetection\\archive2\\Medical mask\\Medical mask\\Medical Mask\\images'\n",
    "        self.annotation_directory = r'C:\\ML\\Datasets\\FaceMaskDetection\\archive2\\Medical mask\\Medical mask\\Medical Mask\\annotations'\n",
    "        self.initial_learning_rate = 1e-4\n",
    "        self.epochs = 30\n",
    "        self.batch_size = 32\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "    # Bütün class variable'ları yeniden belirle\n",
    "    def __init__(self, image_directory, annotation_directory, initial_learning_rate, epochs, batch_size):\n",
    "        # Varsayılanları Değiştir\n",
    "        self.image_directory = image_directory\n",
    "        self.annotation_directory = annotation_directory\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "    # Sadece image_directory ve annotation_directory class variable'larını yeniden belirle\n",
    "    @classmethod\n",
    "    def __init__1(self, image_directory, annotation_directory):\n",
    "        self.__init__()\n",
    "        # Varsayılanları Değiştir\n",
    "        self.image_directory = image_directory\n",
    "        self.annotation_directory = annotation_directory\n",
    "\n",
    "    # Sadece initial_learning_rate, epochs ve batch_size class variable'larını yeniden belirle\n",
    "    @classmethod\n",
    "    def __init__2(self, initial_learning_rate, epochs, batch_size):\n",
    "        self.__init__()\n",
    "        # Varsayılanları Değiştir\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # Görüntüleri diskten etiketleri ile birlikte yükleyerek düzenleyen metod\n",
    "    def load_images(self):\n",
    "        print(\"> Görüntüler yükleniyor...\")\n",
    "        for filename in os.listdir(self.image_directory):\n",
    "            num = filename.split('.')[0]\n",
    "            print('\\r> Yüklenen görüntü: {}'.format(filename), end=\"\")\n",
    "            if int(num) > 1800:\n",
    "                class_name = None\n",
    "                anno = filename + \".json\"\n",
    "                with open(os.path.join(self.annotation_directory, anno)) as json_file:\n",
    "                    json_data = json.load(json_file)\n",
    "                    no_anno = json_data[\"NumOfAnno\"]\n",
    "                    k = 0\n",
    "                    for i in range(0, no_anno):\n",
    "                        class_nam = json_data['Annotations'][i]['classname']\n",
    "                        if class_nam in ['face_with_mask', \"gas_mask\", \"face_shield\", \"mask_surgical\", \"mask_colorful\"]:\n",
    "                            class_name = 'face_with_mask'\n",
    "                            k = i\n",
    "                            break\n",
    "                        elif class_nam in ['face_no_mask,\"hijab_niqab', 'face_other_covering',\n",
    "                                           \"face_with_mask_incorrect\",\n",
    "                                           \"scarf_bandana\", \"balaclava_ski_mask\", \"other\"]:\n",
    "                            class_name = 'face_no_mask'\n",
    "                            k = i\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    box = json_data['Annotations'][k]['BoundingBox']\n",
    "                    (x1, x2, y1, y2) = box\n",
    "                if class_name is not None:\n",
    "                    image = cv2.imread(os.path.join(self.image_directory, filename))\n",
    "                    img = image[x2:y2, x1:y1]\n",
    "                    img = cv2.resize(img, (224, 224))\n",
    "                    img = img[..., ::-1].astype(np.float32)\n",
    "                    img = preprocess_input(img)\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(class_name)\n",
    "\n",
    "        self.images = np.array(self.images, dtype=\"float32\")\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "        print('\\r> Yüklenen görüntü sayısı: ' + str(len(self.images)))\n",
    "        print('> Yüklenen ek açıklama (etiket) sayısı: ' + str(len(self.labels)))\n",
    "        print('>    face_with_mask: ' + str(np.count_nonzero(self.labels == 'face_with_mask', axis=0)))\n",
    "        print('>    face_no_mask  : ' + str(np.count_nonzero(self.labels == 'face_no_mask', axis=0)))\n",
    "\n",
    "    # Daha sonra kullanılacak olan yüz tanıma kategorizasyonu yapacak modelin\n",
    "    #   oluşturulması, disk üzerinde serileştirilerek saklanması, ve serileştirme\n",
    "    #   işleminden elde edilecek verilerin raporlanmasını sağlayan metod.\n",
    "    def build_save_report_model(self):\n",
    "        print(\"> Maske tanıma modeli oluşturuluyor ...\")\n",
    "        # Etiketler kategori oluşturmak için kodlanacak\n",
    "        lb = LabelBinarizer()\n",
    "        labels_loaded = lb.fit_transform(self.labels)\n",
    "        labels_loaded = to_categorical(labels_loaded)\n",
    "\n",
    "        # Verilerin %75'ini eğitim için ve kalan %25'ini de test için kullanabilmek\n",
    "        #   amacıyla veriler eğitim (train) ve test olarak iki bölüme ayrılmaktadır.\n",
    "        (trainX, testX, trainY, testY) = train_test_split(self.images, labels_loaded,\n",
    "                                                          test_size=0.20, stratify=labels_loaded, random_state=42)\n",
    "\n",
    "        # Gerçek zamanlı veri artırma ile eğitim için kullanılacak toplu tensör görüntü verilerini oluşturun\n",
    "        aug = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            zoom_range=0.15,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\")\n",
    "\n",
    "        model = FaceMaskModel()\n",
    "        # Modeli MobileNetV2 ağı üzerine kurmaktayız.\n",
    "        model = model(MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3))))\n",
    "\n",
    "        # Oluşturulan modelin özetini yazdıralım\n",
    "        print(\">\\n> Oluşturulan Modelin Özeti:\")\n",
    "        print(model.summary())\n",
    "        print(\">\")\n",
    "\n",
    "        # Oluşturulan modeli derleyelim\n",
    "        print(\"> Yüz tanıma modeli derleniyor...\")\n",
    "        opt = Adam(lr=self.initial_learning_rate, decay=self.initial_learning_rate / self.epochs)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "        # Derlenen modeli eğitelim\n",
    "        print(\"> Yüz tanıma modeli eğitiliyor...\")\n",
    "        history = model.fit(\n",
    "            aug.flow(trainX, trainY, batch_size=self.batch_size),\n",
    "            steps_per_epoch=len(trainX) // self.batch_size,\n",
    "            validation_data=(testX, testY),\n",
    "            validation_steps=len(testX) // self.batch_size,\n",
    "            epochs=self.epochs)\n",
    "\n",
    "        # Test setiyle eğitilen modelin tahmin performansına bakalım (keras.engine.training.Model.predict)\n",
    "        print(\"\\n> Girdi örnekleri için çıktı tahminleri oluşturuluyor...\")\n",
    "        predIdxs = model.predict(testX, batch_size=self.batch_size)\n",
    "\n",
    "        # Test setindeki her bir görüntü için, en büyük tahmin olasılığına karşılık gelen etiketin dizinini bulmamız gerekiyor.\n",
    "        predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "        # Elde edilen sınıflandırmayı rapolayalım\n",
    "        print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))\n",
    "\n",
    "        # Oluşturduğumuz ve Eğittiğimiz modeli dizin haline getirerek (serialize) diske kaydedelim\n",
    "        print(\"> Maske tanıma modeli diske yazılıyor...\")\n",
    "        model.save(\"mask_detector_test.model\", save_format=\"h5\")\n",
    "\n",
    "        # Eğitimden kaynaklanan kayıp (loss) ve doğruluk (accuracy) verilerini raporlayalım\n",
    "        print(\"> Maske tanıma modeli eğitim istatistik grafikleri oluşturuluyor...\")\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0, self.epochs), history.history[\"loss\"], label=\"Eğitim kaybı\")\n",
    "        plt.plot(np.arange(0, self.epochs), history.history[\"val_loss\"], label=\"Doğrulama kaybı\")\n",
    "        plt.plot(np.arange(0, self.epochs), history.history[\"accuracy\"], label=\"Eğitim doğruluğu\")\n",
    "        plt.plot(np.arange(0, self.epochs), history.history[\"val_accuracy\"], label=\"Doğrulama doğruluğu\")\n",
    "        plt.title(\"Eğitim Kaybı ve Doğruluğu\")\n",
    "        plt.xlabel(\"Dönem #\")\n",
    "        plt.ylabel(\"Kayıp/Doğruluk\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(\"FaceMaskTrainingStats.png\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"> Maske tanıma modeli oluşturuldu.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yüz Maskesi Modeli Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskTraining = FaceMaskTraining(\n",
    "    r'C:\\ML\\Datasets\\FaceMaskDetection\\archive2\\Medical mask\\Medical mask\\Medical Mask\\images',\n",
    "    r'C:\\ML\\Datasets\\FaceMaskDetection\\archive2\\Medical mask\\Medical mask\\Medical Mask\\annotations', \n",
    "    1e-4, \n",
    "    30, \n",
    "    32)\n",
    "maskTraining.load_images()\n",
    "maskTraining.build_save_report_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
